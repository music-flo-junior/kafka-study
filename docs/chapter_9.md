### 챕터 9. 데이터 파이프라인 구축하기

> **데이터 파이프라인이란?**
: 서로 다른 여러 시스템 간의 데이터 이동/흐름
> 
- 데이터 파이프라인 이용 사례
    1. 아파치 카프카가 두 개의 엔드 포인트 중 하나가 되는 데이터 파이프라인 구축
        - ex. 카프카의 데이터를 s3에 넣거나, 몽고DB의 데이터를 카프카로 가져온다
    2. 서로 다른 두 개의 시스템 중간에서 카프카를 중개 역할로 사용하는 파이프라인 구축
        - ex. 트위터에서 카프카로 전달 후 카프카에서 ES로 전달하는 방식
- 카프카 커넥트 API: 데이터 파이프라인 구축을 쉽게 해줄 수 있는 API

## 9.1 데이터 파이프라인 구축 시 고려사항

### 9.1.1 적시성(timeliness)

> 적시성: 어떤 일이 적절한 시점에 이루어지는 것 (시간 엄수)
> 
- 좋은 데이터 통합 시스템은 서로 다른 파이프라인의 서로 다른 적시성(timeliness) 요구사항을 지원
- 실시간(즉시처리) 파이프라인부터 시간 단위 배치(일정 시간 모아서 처리) 파이프라인까지 지원하는 버퍼로 사용 가능

### 9.1.2 신뢰성

- 단일 장애점(single point of failure)을 피하고 모든 종류의 장애 발생 시에 신속하고 자동화된 복구를 . 할수 있어야 함
- 데이터 파이프라인은 시스템에 데이터가 전달되는 경로를 제공하므로 수초 이상의 장애가 발생 . 시전체 시스템에 큰 지장을 줄 수 있다.
- 최소 한 번(at-least-once), 정확히 한 번(exactly-once) 데이터 전달 요구사항을 보장한다.

### 9.1.3 높으면서도 조정 가능한 처리율

- 매우 높은 처리량(throughput)을 갖도록 확장될 수있어야 하며, 불시에 처리량이 증가하더라도 조정할 수 있어야 한다.
- 카프카는 데이터를 쓰는 프로듀서와 읽는 컨슈머 간의 버퍼 역할을 하므로 컨슈머와 프로듀서의 처리량을 연관시키지 않아도 된다.
- 카프카는 높은 처리량의 분산 시스템이다. 요구사항에 맞게 카프카 파이프라인이 확장하고, 카프카 커넥트 API를 사용하면 확장은 물론 다중 스레드를 사용한 병행 처리도 가능하다.

### 9.1.4 데이터 형식

- 서로 다른 데이터 형식을 조화시키는 것이 필요하다.
    - ex. Avro : XML과 관계형 데이터 / ES : Json / 하둡: Parquet, S3: CSV 형식 등
- 카프카 자체와 커넥트 API는 데이터 형식에 구애받지 않는다.
- 범용적인 데이터 파이프라인을 제공하는 통합 프레임워크에서는 다양한 소스와 싱크의 서로 다른 동작에 따른 차이점도 처리할 수있어야 한다.

### 9.1.5 변환

- ETL (Extract-Transform-Load)
    - 추출-변환-적재
    - 서로 다른 소스 시스템에서 데이터를 가져와서(추출) → 적절한 형식이나 구조로 변환 후 (변환) → 다른 시스템에 저장(적재)
    - ETL의 문제점
        - 소스 데이터 형식이나 구조가 파이프라인에서 변환되어 전달
            
            → 파이프라인에 연결된 대상 시스템의 더 아래 단에서 데이터를 처리하는 사용자나 애플리케이션의 유연성을 떨어뜨림
            
- ELT (Extract-Load-Transform)
    - 추출-적재-변환
    - 대상 시스템에 전달되는 데이터가 가능한 한 소스 데이터와 유사하게 되도록 데이터 파이프라인에서는 최소한의 변환(데이터 형식만 변환)만 수행한다.
    - 따라서 대상 시스템에서 원시(raw) 데이터를 받고 모든 변환도 수행한다.
    - 필드값이 바뀌면 해당 시스템에서만 수정하면 되므로 해결은 간편하지만 변환에 필요한 대상 시스템의 CPU와 스토리지가 부담된다는 단점이 있다.

### 9.1.6 보안

- 데이터 파이프라인 보안 체크
    - 누 카프카로 수집되는 데이터에 접근할 수 있는가?
    - 파이프라인을 거쳐 가는 데이터가 암호화되고 있는가?
    - 파이프라인을 수정할 수 있도록 허용된 사람은 누구인가?
    - 접근이 제어된 시스템에서 데이터를 파이프라인으로 읽거나 쓸 때, 인증 기능을 올바르게 사용하고 있는가?
- 카프카는 암호화된 데이터의 네트워크 전송을 허용하며 SASL(Simple Authentication and Security Layer) 인증 지원한다. (인증되지 않은 누군가가 시스템에 접근 X)
- 카프카는 시스템 접근을 추적 관리하기 위해 감사로그(audit log)를 제공한다.

### 9.1.7 장애처리

- 사전에 장애 처리에 관한 계획 세우기
    - 잘못된 데이터가 파이프라인으로 유입되는 것을 방지할 수 있을까?
    - 분석될 수없는 데이터를 복구할 수 있을까?
    - 결함 있는 데이터를 바로 잡아 다시 처리할 수있을까?
    - 잘못된 데이터가 정상인 것처럼 보여서 수 일이 지난 후 비로소 문제가 생겼다는 것을 알면?

→ 카프카는 모든 데이터를 긴 시간 동안 저장하므로 해당 시점에 맞게 이전으로 돌아가 에러 복구 가능

### 9.1.8 결합과 민첩성

데이터 파이프라인의 가장 중요한 목표는 데이터를 제공하는 소스와 데이터를 받아 사용하는 대상을 분리하는 것이지만 의도하지 않은 결함이 발생할 수 있음

1. 임기응변식 파이프라인
    1. 연결을 원하는 어플리케이션을 추가하며 특정 엔드포인트와 강하게 결합되면 설치와 유지보수 및 모니터링에 큰 노력이 요구된다.
2. 메타데이터 유실
    1. 스키마 메타데이터를 보존하지 않고 스키마 진화(버전 호환성)을 허용하지 않는다면 데이터가 유실되거나 소스와 대상 시스템이 강하게 결합된다.
3. 과도한 처리
    1. 파이프라인에서 너무 많은 처리를 하면 후속으로 개발되는 시스템은 해당 값들과 강하게 결속된다.

## 9.2 카프카 커넥트 vs 프로듀서/컨슈머

- 카프카에서 데이터를 쓰거나 읽을 때에는 **`프로듀서와 컨슈머를 사용 하는 것`** vs **`커넥트 API와 커넥터(Connector)를 사용하는 것`**을 선택할 수있다.
- **`프로듀서와 컨슈머를 사용 하는 것`**
    - 카프카 클라이언트 애플리케이션을 연결하기 원하는 외부 애플리케이션 코드를 변경할 수 있을 때 사용
    - 카프카에 데이터를 쓰거나 읽기를 원할 때 사용
- **`커넥트 API와 커넥터(Connector)를 사용하는 것`**
    - 코드를 작성하지 않았고 변경도 할 수 없는 모든 외부 시스템(ex. S3, 하둡 HDFS, ES, DB 등)에 카프카를 연결할 때는 카프카 커넥터 사용
    - 카프카에서 데이터를 읽어서 외부 시스템에 쓰는 데 사용되는 컴포넌트 클래스가 커넥터
    - 커넥트 API
        - 구성 관리, 오프셋 스토리지, 병행 처리, 에러 처리, 서로 다른 데이터 형식 지원, 표준 관리 REST API 등의 기능 제공
        - 외부 데이터스토어로 데이터를 전달하고 받는것에만 집중 가능

## 9.3 카프카 커넥트

- 아파치 카프카의 일부로 포함
- 다른 데이터스토어 간에 데이터를 이동하기 위해 확장성과 신뢰성 있는 방법 제공
- 커넥터 플러그인을 개발하고 실행하기 위한 API와 런타임 제공
- 카프카 커넥트
    - 여러 개의 작업 프로세스들로 실행
    - 카프카 플러그인을 작업 프로세스에 설치한 후 REST API를 사용해서 특정 구성으로 실행되는 커넥터를 구성하고 관리
- 커넥터
    - 대용량 데이터를 병행 처리로 이동시키고, 태스크(task)들을 추가로 시작시킨다.
    - 소스(source)커넥터와 싱크(sink) 커넥터 두 종류가 있다.
        - 소스 커넥터 task: 소스 시스템으로부터 데이터를 읽어서 커넥터 데이터 객체로 작업 프로세스에 제공
        - 싱크 커넥터 task 작업 프로세스로부터 커넥트 데이터 객체를 받아서 대상 시스템에 쓴다
            - 컨버터(converter)를 사용하여 다양한 형식의 데이터 객체들을 카프카에 저장

### 9.3.1 커넥트 실행하기

- 카프카 커넥트와 커넥트 API는 카프카에 포함되어 배포되므로 별도 설치 필요 X
- 실제 업무에서 대용량의 데이터를 이동하거나 여러 커넥터를 실행할 때에는 하나 이상의 별도 서버에서 커넥트 작업 프로세스를 실행

```java
# bin/connect-distributed.sh config/connect-distributed.properties
```

- 핵심 속성
    - bootstraps.server (브로커 리스트)
    - [group.id](http://group.id) (같은 작업 프로세스를 갖는 그룹 ID)
    - key.converter, value.converter (데이터 컨버터 형식)
- rest api 사용 가능

```java
$ curl http://localhost:8083
$ curl http://localhost:8083/connector-plugins
```

### 9.3.2 커넥터 사용 예시

- 파일 소스와 파일 싱크 → 책 내용 참고
- MySQL → ElasticSearch로 → 내용 참고

### 9.3.3 커넥트 자세하게 알아보기

- 커넥트 동작방식 이해

**커넥터와 태스크**

커넥터 플러그인에서는 커넥터 API를 구현하며, 커넥터(connector)와 태스크(task)를 포함한다.

- 커넥터
    - 커넥터에서 얼마나 많은 태스크가 실행되어야 하는지 결정한다.
    - 데이터 복사 작업을 각 태스크에 어떻게 분담할지 결정한다.
    - 작업 프로세스로부터 태스크의 구성 정보를 얻는다.
- 태스크
    - 데이터 입출력의 책임
    - 소스: 외부 데이터를 읽어서 레코드들의 리스트를 반환
    - 싱크: 카프카의 레코드들을 받아서 외부 시스템에 쓴다

**작업 프로세스**

- 커넥터와 커넥터의 구성을 정의하는 HTTP 요청을 처리하는 책임을 갖는다.
- 커넥터 구성을 저장하고, 커넥터와 태스크를 시작시킨다.
- 모든 작업 프로세스의 작업량이 균등하게 조정되도록 새로 합류한 작업 프로세스에게 커넥터와 태스크가 할당된다.
- 소스와 싱크 커넥터 모두의 오프셋을 자동으로 커밋하고 에러가 생길 때 재시도 처리하는 책임을 갖는다.