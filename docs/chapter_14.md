# 챕터 14. 스트림 처리

전통적으로 카프카는 이벤트 스트림을 전달하는 것만 가능할 뿐 메시지 처리나 변환은 불가능한 강력한 메시지 버스로 인식되어 왔다.
신뢰성 있는 전달이 가능했기에 카프카는 스트림 처리 시스템을 위한 저장소 역할을 할 수 있었다.

처음에는 단순한 메시지 버스로, 나중에는 데이터 통합 시스템으로 카프카의 활용이 늘어나며 많은 회사들은 내용상으로 중요하고, 완벽한 순서를 유지하며 오랜 시간동안 저장되어 있고,
스트림 처리 프레임워크를 사용해서 처리만 하면 결과가 나오는 데이터 스트림을 대거 보유하게 되었다.

카프카는 단순한 널리 쓰이는 스트림 프로세싱 프레임워크를 위한 데이터 스트림 저장소 역할을 넘어섰다. 카프카 스트림즈라 불리는 강력한 스트림 처리 라이브러리를 클라이언트 라이브러리의 일부로 포함한다.

## 스트림 처리란 무엇인가?

스트림 처리가 무엇을 의미하는가에 대해서는 다소 혼란이 있을 수 있다. 이 주제에 대한 많은 정의들이 세부 구현, 성능 요구 조건, 데이터 모델, 그 외 많은 요소를 섞어두기 때문이다.

스트림 처리의 기본 개념은 **무한히 늘어나는 데이터 세트를 추상화 한 것**이라는 것이다. **무한**이라함은 끝없이 계속해서 늘어난다는 의미다.

이벤트 스트림이라는 이 단순한 모델이 우리가 분석하고자 하는 모든 비즈니스 활동을 나타낼 수 있음에 주목하라. (신용카드 결제, 주식 거래, 택배 배송, 게임에서의 이동)

이벤트 스트림 모델에는 몇몇가지 추가적인 속성이 있다.

### 이벤트 스트림에는 순서가 있다.

- 이벤트는 그 자체로 다른 이벤트 전에, 혹은 후에 발생했다는 의미를 가진다. 
금융 이벤트를 예로 들면, 출금 이후 입금이 진행되는 것이다.

### 데이터 레코드는 불변하다.

- 이벤트는 한번 발행한 후로 고칠 수 없다. 취소된 금융 거래는 사라지지 않는다. 추가로 취소 이벤트가 쓰여질 뿐이다. 
이것은 데이터 스트림과 데이터베이스 테이블의 또 다른 차이이기도 하다.

### 이벤트 스트림은 재생(replay)이 가능하다.

- 대부분에 애플리케이션에서 재생이 불가능한 스트림을 생각하는 것이 어려운 일은 아니지만, 몇달 전, 심지어 몇년 전에 발생한 raw stream을 그대로 재생할 수 있다는 것은 매우 중요하다.

이제 이벤트 스트림이 무엇인지 알았으므로, 스트림 처리가 무엇인지 이해해보자. 스트림은 하나 이상의 이벤트 스트림을 계속해서 처리하는 것을 의미한다.
스트림 처리는 요청-응답, 배치 처리와 마찬가지로 프로그래밍 패러다임중 하나이다. 스트림 처리가 소프트웨어 아키텍처에서 차지하는 위치를 이해하기 위해 다른 프로프래밍 패러다임을 잠시 살펴보자.

### 요청 - 응답

- 응답 시간이 1밀리초 미만 ~ 몇 밀리초 수준인 패러다임으로 가장 지연이 작은 패러다임이다. 다만 처리 방식이 보통 블로킹 방식이라 시스템이 응답을 보내줄 때까지 대기하는 것이 보통이다.
  (포스 시스템, 신용카드 결제 시스템 등)

### 배치 처리

- 이것은 지연이 크지만, 처리량 역시 크다. 이러한 부류의 처리 시스템은 매일 새벽 2시라던지, 매 시간이라던지 사전에 설정된 시간에 동작한다. 일단 필요한 모든 데이터를 읽고 모든 출력 데이터를 쓰고, 다음 번 실행 시간까지 대기하는 것이다.
- 처리 시간이 몇분에 불과한 것 부터 몇시간 까지 다양하다.
- 사용자들은 결과물을 볼때 시간이 지난 데이터임을 감안하고 본다.

### 스트림 처리

- 이것은 연속적일고 또 논블로킹하게 동작하는 방식이다. 스트림 처리는 이벤트 처리에 2밀리초 정도 기다리는 응답-요청 방식과 하루 한 번 작업이 실행되고 완료되는데 8시간이 걸리는 배치의 격차를 메워준다.
- 대부분의 비즈니스는 즉시 응답을 요구하지도 않지만, 그렇다고 다음 날 까지 기다릴수도 없다. 대부분의 비즈니스 프로세스는 **연속적으로** 발생하며, 계속 비즈니스 리포트가 업데이트 되고 최일선을 비즈니스 애플리케이션들이 역시 계속해서 응답할 수 있다면, 굳이 수 밀리초의 
  응답을 기다릴 필요가 없다.
- 의심스러운 신용카드 결제나 네트워크 사용 내역을 알린다거나, 수요와 공급에 맞춰 실시간으로 간격을 조정한다거나. 물품 배송을 추적하는 것 등이 해당된다.

이러한 스트림 처리에 대한 정의는 특정한 프레임워크나 API, 기능을 요구하지 않는다. **무한한 크기의 데이터 세트에서 연속적으로 데이터를 읽어와서 뭔가를 하고, 결과를 내보내는 한 우리는 스트림 처리를 수행하고 있는 것**이다.

## 스트림 처리 개념

스트림 처리는 다른 형태의 데이터 처리와 매우 비슷하다. 결국 데이터를 읽고, 무엇인가 처리를 한 뒤 어딘가에 결과물을 쓰는 식의 코드를 작성한다.
다만 스트림 처리 고유의 핵심 개념이 몇개 있기 때문에 처음 개발하게 되면 이것 때문에 혼란을 일으키키도 한다.

### 토플로지

스트림 처리 애플리케이션은 하나 이상의 처리 토폴로지를 포함한다. 하나의 처리 토폴로지는 하나 이상의 소스 스트림, 스트림 프로세서의 그래프, 하나 이상의 싱크 스트림이 서로 연결 된 것으로써,
하나 이상의 소스 스트림에서 시작 된 이벤트 스트림은 연결 된 스트림 프로세서들을 거쳐사면서 처리되다가 마지막에 하나 이상에 싱크 스트림에 결과를 쓰는것으로 끝나게 된다.

각각의 스트림 프로세서는 이벤트를 변환하기 위해 이벤트 스트림에 가해지는 연산 단계라고 할 수 있다.

### 시간

시간이란 스트림 처리에서 가장 중요한 개념인 동시에 많은 경우 가장 혼란스러운 개념일 것이다. 스트림 처리의 맥락에서 대부분의 스트림 애플리케이션이 시간 윈도우에 대해 작업을 수행하는 만큼 시간에 대해 공통적인 개념을 가지는 것이 중요하다.
예를 들어서, 최근 5분 사이의 주가의 이동평균을 구하는 스트림 애플리케이션을 생각해보자. 이 경우 데이터를 쓰는 쪽 프로세스가 네트워크 문제로 인해 두시간동안 오프라인이었다가 두 시간치 데이터를 한번에 리턴할 때 무엇을 해야할 지 알아야 한다.
대부분의 데이터는 일찌감치 지나가서 연산 결과가 이미 어딘가에 저장되었을 5분 길이의 시간 윈도우에 대해서나 의미가 있을 것이다.

#### 이벤트 시간

- 이것은 다루고자 하는 이벤트가 발생하여 레코드가 생성 된 시점이다.
- 무엇인가 측정이 수행 된 시각, 상품이 팔린 시각 등

#### 로그 추가 시간

- 이것은 이벤트가 카프카 브로커에 전달되어 저장 된 시점이다. 접수 시간이라고도 불린다.
- 스트림 처리에선 이벤트 시간이 관심사이기 때문에 덜 중요한 시간 개념이다.

#### 처리 시간

- 스트림 처리 애플리케이션이 뭔가 연산을 수행하기 위해 이벤트를 받은 시간이다.
- 이벤트가 발생한 뒤 몇 밀리초, 몇 시간, 며칠 뒤 일수도 있다.
- 동일한 이벤트라 하더라도 정확히 언제 스트림 처리 애플리케이션이 이벤트를 읽었느냐에 따라서 전혀 다른 타임스탬프가 주어진다.

카프카 스트림즈는 `TimestampExtractor` 인터페이스를 활용해서 각각의 이벤트 시간을 부여한다. 카프카 스트림즈를 사용하는 개발자는 이 인터페이스의 서로 다른 구현체를 사용하므로써 위에서 설명한 시간 개념을 사용한다.

카프카 스트림즈가 결과물을 토픽에 쓸 때 다음과 같은 규칙에 따라서 이벤트에 타임스탬프를 부여한다.

- 결과 레코드가 입력으로 주어진 레코드에 직접적으로 대응 될 경우, 동일한 타임 스탬프를 사용한다.
- 결과 레코드가 집계의 결과일 경우 집계의 사용 된 레코드의 최대 값을 타임스탬프로 사용한다.
- 결과 레코드가 두 스트림을 조인한 결과일 경우 큰쪽을 레코드의 타임스탬프로 사용한다.
- 입력과 상관없이 특정한 스케줄에 따라 데이터를 생성하는 카프카 스트림즈에 의해 생성 된 결과일 경우, 애플리케이션의 현재 시각으로 결정한다.

> #### 시간을 다룰때는 timezone을 주의하라
> 시간을 다룰때는 시간대에 주의해야 한다. 파이프라인이 표준화 된 시간대 하나만 쓰거나 하지 않으면, 스트림 작업이 혼란스러운 결과를 내놓거나 심지어 의미가 없을 수 있다.

### 상태

각각의 이벤트를 따로 따로 처리해야만 한다면 스트림 프로세싱은 매우 간단해진다. 

- 카프카에서 온라인 쇼핑 트랜잭션 스트림을 읽어서 담당자에게 메일을 보내는게 할일의 전부라면 코드 몇줄만으로 충분하다.

하지만 스트림 처리는 다수의 이벤트가 포함되는 작업을 할때 정말로 재미있어 진다. 

- 이벤트를 종류별로 집계
- 이동 평균 계산
- 2개의 스트림을 조인해 확장 정보 스트림 생성 등

이러한 경우 각각의 이벤트 자체만을 살펴보는 것 만으로 충분하지 않다. 지금 한시간 동안 발생한 이벤트 수나 조인, 합계 및 평균을 계산하는 모든 이벤트 등 더 많은 정보를 관리해야 한다.
우리는 이러한 정보를 **상태(state)** 라고 부른다.

스트림 처리에는 다음과 같은 상태가 있다.

#### 로컬 혹은 내부 상태

- 스트림 처리 애플리케이션의 특정 인스턴스에서만 사용할 수 있는 상태다. 애플리케이션의 메모리에 관리된다.
- 매우 빠르지만, 메모리 크기의 제한이 있다. 
- 스트림 처리의 많은 디자인 패턴들은 데이터를 분할해서 한정 된 크기의 로컬 상태를 만들어 처리 가능한 서브 스트림으로 만든다.

#### 외부 상태

- 외부에서 유지되는 상태는 대부분 카산드라와 같은 NoSQL을 사용해서 저장된다.
- 크기에 제한이 없고, 여러 애플리케이션 인스턴스에서 접근이 가능하다.

### 스트림-테이블 이원성

데이터베이스 테이블은 테이블을 쿼리함으로써 레코드의 변이가 가능하다. 예를 들어 고객 테이블을 조회하므로써 현재 시점의 모든 고객 연락처를 찾을 수 있다.
하지만 과거 상태는 찾을 수 없을 것 이다. (특별히 로직을 작성한게 아니라면)

스트림은 변경내역을 저장한다. 스트림은 변경을 유발하는 이벤트의 연속이다. 테이블은 여러 상태 변경의 결과물인 현재 상태를 저장한다.
이러한 점에서 볼 때 스트림과 테이블은 같은 동전의 양면임이 명백하다. 

테이블을 스트림으로 변환하기 위해서는 테이블을 수정한 변경 내역을 잡아내야 한다. 모든 추가, 변경, 삭제 이벤트를 가져와 스트림에 저장하면 된다.
많은 데이터베이스에서는 이러한 변경점들을 잡아내기 위한 CDC 솔루션을 제공한다.

스트림을 테이블로 변환하기 위해서는 스트림에 포함된 모든 변경 사항을 테이블에 적용해야 한다. 이러한 작업을 두고 **스트림을 구체화**한다고 한다. 메모리든 내부 상태 저장소든 외부 데이터베이스든 테이블을 생성한 뒤 이벤트를 모두 읽어 상태를 변경한다.
이 작업이 끝나면 특정 시점의 상태를 나타내는 테이블을 얻을 수 있다.

### 시간 윈도우

대부분의 스트림 작업은 시간을 윈도우라 불리는 구간 단위로 잘라서 처리한다. 

- 이동 평균을 계산
- 스트림을 조인
- 이번 주 많이 팔린 상품

즉, 동일한 시간 간격 안에 발생한 이벤트끼리 조인한다.

#### 윈도우 크기

- 이벤트의 평균을 구할 때 시간이 중요하다.
- 윈도우 크기가 커질수록 이동 평균은 완만해지지만, 랙 역시 커진다.
- 카프카 스트림은 윈도우의 크기가 비활동 기간에 길이에 따라 결정되는 **세션 윈도우**를 지원한다.
- 개발자가 세션 간격을 정의하면, 세션 간격보다 작은 시간을 두고 연속적으로 도착한 이벤트는 하나의 세션에 속하게 된다.

#### 시간 윈도우의 진행 간격

- 5분 단위 평균은 매분, 매초, 혹은 새로운 이벤트가 도착할 때 마다 업데이트 될 수 있다.
- 윈도우의 크기와 윈도우 사이에 고정된 시간 간격이 같은 윈도우를 **호핑 윈도우**라 한다.
- 진행 간격과 윈도우 크기가 같은 경우를 **텀블링 윈도우**라고 한다.


> #### 호핑 윈도우
> - 00:00 ~ 00:05 (첫 번째 윈도우)
> - 00:01 ~ 00:06 (두 번째 윈도우)
> - 00:02 ~ 00:07 (세 번째 윈도우)

> #### 텀블링 윈도우
> - 00:00 ~ 00:05 (첫 번째 윈도우)
> - 00:05 ~ 00:10 (두 번째 윈도우)
> - 00:10 ~ 00:15 (세 번째 윈도우)

#### 윈도우를 업데이트 할 수 있는 시간

- 우리가 오전 00:00 부터 00:05 까지의 윈도우에 대해 5분 단위 이동 평균을 계산했다.
- 한시간 뒤 00:02인 레코드가 추가로 주어질 경우 결과를 업데이트를 할 것인지, 지난 값을 가만히 둘 것인지에 대한 시간을 정의해야 한다.
- 이벤트가 그 시간보다 지연된다면 무시한다.

### 처리 보장

스트림 처리 애플리케이션에 있어서 핵심적인 요구 조건 중 하나는 장애가 발생했을 경우에도 각각의 레코드를 한번만 처리할 수 있는 능력이다.
정확히 한번 보장이 없는 경우 스트림 처리는 정확한 결과가 요구되는 상황에서 사용 할 수 없다. 

## 스트림 처리 디자인 패턴

모든 스트림 처리 시스템은 서로 다르다. 가장 단순한 형태로 컨슈머, 처리 로직, 프로듀서를 엮어 둔 경우가 있는가 하면, 
클러스터 상에서 기계 학습 라이브러리와 함께 돌아가는 스파크 스트리밍과 같은 것도 있다.
여기에는 스트림 처리 아키텍처의 공통된 요구 사항에 대한 잘 알려진 해법인 기본 패턴이 있다. 

### 단일 이벤트 처리

가장 단순한 스트림 처리 패턴은 각각의 이벤트를 개별적으로 처리하는 것 이다. 이것은 맵/필터 패턴이라고도 알려져 있는데, 이 패턴이 불필요한 이벤트를 스트림에서 걸러내거나,
각 이벤트를 변환하기 위해 사용되는 경우가 많다.

이 패턴에서는 스트림 처리 애플리케이션은 각각의 이벤트를 읽어와서 수정한 뒤 수정된 이벤트를 다른 스트림에 쓴다. 

- 스트림으로 부터 로그 메시지를 일겅와서 ERROR 이벤트를 우선순위가 높은 스트림에, 나머지를 낮은 스트림에 쓰기
- JSON 이벤트를 읽어 Avro 형식으로 쓰기

이러한 애플리케이션은 상태를 보관 할 필요가 없다. 상태를 복구할 필요가 없기 때문에 장애 복구나 부하 분산이 매우 쉽다.

### 로컬 상태와 스트림 처리

대부분의 스트림 처리 애플리케이션은 윈도우 집계와 같이 정보의 집계에 초점을 맞춘다. 매일의 주식 최저가와 최고가를 찾고, 주가의 이동 평균을 구하는 것이 이러한 애플리케이션의 예가 될것이다.

이처럼 집계를 할 때는 상태를 유지할 필요가 있다. 주식의 일별 최저가와 평균가를 계산하기 위해서는 최소값과 총합, 그리고 지금까지의 본 레코드 수를 저장해 놓아야 한다.
이 예제에서 각각의 작업은 그룹별 집계이기 때문에 이것은 공유 상태가 아닌 로컬 상태를 사용해서 수행할 수 있다.
파티셔너를 활용해 같은 주식은 같은 파티션에 저장하고, 컨슈머가 이벤트를 읽어오면 부분집합이 보장된다.

스트림 처리 애플리케이션은 로컬 상태를 보유하는 순간 복잡해진다. 다음과 같은 내용을 고려해야 한다. 

#### 메모리 사용

- 로컬 상태가 인스턴스가 사용 가능한 메모리 안에 들어갈 수 있어야 한다. 

#### 영속성

- 애플리케이션 인스턴스가 종료되었을 때 상태가 유실되지 않고, 인스턴스가 재실행 되거나 다른 인스턴스에 의해 복구될 수 있음을 확신할 수 있어야 한다.
- 카프카 스트림즈는 내장 된 RocksDB를 사용하므로써 로컬 상태를 인메모리로 저장함과 동시에 재시작과 동시에 빠르게 복구가 가능하도록 디스크에 데이터를 저장한다.

#### 리밸런싱

- 파티션은 이따금 다른 컨슈머에 다시 할당 될 수 있다. 재할당이 발생하면 파티션을 상실한 애플리케이션 인스턴스는 마지막 상태를 저장하므로써 해당 파티션을 할당받은 인스턴스가 이전 상태를 복구할 수 있도록 해야한다.

### 다단계 처리/리파티셔닝

그룹별 집계가 필요할 때 로컬 상태를 사용하면 좋다. 하지만 모든 정보를 사용해서 내야 하는 결과가 필요하다면 어떨까?

- 매일 상위 주식 10개를 계산해야 한다.
- 다른 인스턴스에 할당된 파티션에 분산되어 있을 수 있다. 
- 애플리케이션 인스턴스에서 작업하는 것 만으로는 충분하지 않다.

이 경우에는 두가지로 분리해야 한다. 

- 각 주식별 상승/하락을 계산한다.
- 하나의 파티션을 가진 새로운 토픽에 결과를 쓴다.
- 이 파티션을 애플리케이션 인스턴스에서 읽어 매일 상위 10개 주식을 찾는다.

### 외부 검색을 사용하는 처리: 스트림 테이블 조인

스트림 처리를 할 때 때로는 외부 데이터를 스트림과 조인해야 한다. 
거래 내역을 데이터베이스에 저장된 규칙을 사용해서 검증하거나, 사용자 클릭 내역을 클릭한 사용자 정보와 합쳐서 확장하는 것 등이 예가 될 수 있다.

데이터 확장을 위해 외부 검색을 수행하는 경우는 다음과 같다.

- 클릭 이벤트가 발생해 스트림으로 들어온다.
- 스트림에 들어온 데이터를 프로필 데이터베이스에서 검색하여 성별과 나이를 추가한다.
- 이 이벤트를 다른 토픽에 쓴다.

이 단순한 발상의 문제는 외부 검색이 각각의 레코드를 처리하는데 지연을 발생시키는 것이다. 외부 저장소에 걸리는 추가 부하도 용인하기 힘들다.

성능과 가용성의 두마리 토끼를 모두 잡기 위해서는 저장 된 데이터를 캐시할 필요가 있다. 문제는 이 캐시를 관리하는게 만만치 않다. 어떻게 하면 캐시의 정보가 만료되지 않도록 할 수 있을까?
만약 데이터베이스에 가해지는 이벤트를 자주 가져올 경우 여전히 DB를 건들인다. 그렇다고 새 이벤트를 가져오는데 시간이 많이 걸리면 만료된 정보로 스트림 처리를 하게 된다.

하지만, 데이터베이스에 가해지는 모든 변경점을 이벤트 스트림에 담을 수 있다면, 스트림 처리 작업이 이 스트림을 받아와서 처리할 수 있다.
데이터베이스 처리 내역을 이벤트 스트림으로 받아오는 것을 CBC라고 하며, 카프카 커넥트를 활용할 수 있다.

### 테이블 - 테이블 조인

지금까지는 테이블과 이벤트 스트림이 동등한지를 살펴보았다. 스트림과 테이블을 조인할 수 있음을 알아보았다. 그렇다면 조인 연산에서 양쪽에 테이블을 사용할수도 있다.
두 개의 테이블을 조인하는 것은 언제나 윈도우 처리되지 않는 연산이며, 작업이 실행되는 시점에서 양 테이블의 현재 상태를 조인한다.
카프카 스트림에서는 동일한 방식으로 파티션 된 동일한 키를 가지는 두개의 테이블에 대해 동등 조인을 수행할 수 있다.

카프카 스트림즈는 두개의 테이블에 대해 외래 키 조인을 지원한다. 한 스트림 테이블의 키와 다른 스트림 혹은 테이블의 임의의 필드를 조인할 수 있는 것이다.

### 스트리밍 조인

두 개의 실제 이벤트 스트림을 조인해야 할 경우도 있다. 두개의 스트림을 조인할 경우, 한쪽 스트림에 포함된 이벤트를 같은 키값과 함께 같은 시간 윈도우에 발생한 다른쪽 스트림 이벤트와 맞춰야 하기 때문에, 
과거와 현재 모든 이벤트를 조인하게 된다. 이것 때문에 **윈도우 조인**이라고도 불린다.

카프카 스트림즈는 두 스트림이 똑같이 조인 키에 대해 파티셔닝 되어 있을 경우 동등 조인을 지원한다. 사용자의 검색 이벤트와 클릭 이벤트가 같은 파티션에 있으면 조인을 수행할 수 있다.

### 비순차 이벤트

잘못 된 시간에 도착한 이벤트를 처리하는 것은 스트림 처리는 물론이고 전통적인 ETL 시스템에도 어려운 일이다. 비순차 이벤트는 자주 발생할 수 있다.

스트림 애플리케이션은 이런 상황을 처리할 수 있어야 한다. 이를 위해 다음과 같은 일들을 해야한다.

- 이벤트가 순서를 벗어났음을 알아차릴 수 있어야 한다. 
- 비순차 이벤트의 순서를 복구할 수 있는 시간 영역을 지정한다.
- 이벤트를 묶을 수 있어야 한다. 
- 결과를 변경할 수 있어야 한다. 

카프카 스트림즈는 언제나 집계 결과를 토픽에 쓴다. 대부분 로그 압착이 설정되어 있어 마지막 밸류값만 유지된다. 

### 재처리하기

마지막으로 중요한 패턴은 이벤트를 재처리하는 것이다. 두가지 변형이 있다.

- 새로 개선된 스트림 처리 애플리케이션이 있다. 구버전에서 사용하던 이벤트 스트림을 신버전 애플리케이션에서 읽어와서 새로운 결과 스트림을 쓴다.
- 기존의 스트림 처리 애플리케이션에 버그가 많아 고친 후 재처리를 한다.

### 인터랙티브 쿼리

스트림 처리 애플리케이션은 상태를 보유하며, 이 상태는 애플리케이션의 여러 인스턴스에 분산될 수 있다. 스트림 처리 애플리케이션의 사용자는 결과 토픽을 읽어들임으로써 처리 결과를 받아볼 수 있다.
하지만 상태 저장소 그 자체에서 바로 결과를 읽어 올 필요가 있다. 처리 결과가 테이블 형태인 경우 흔하며, 결과 스트림이 곧 테이블에 대한 업데이트 스트림일 경우이다.

카프카 스트림즈는 스트림 처리 애플리케이션의 상태를 쿼리하기 위한 API를 지원한다.

## [예제로 보는 카프카 스트림즈](../kotlin-example/src/main/kotlin/KafkaStreams.kt)

(소스 참조..)
(추가로 필요한 경우 카프카 스트림즈는 별도로.. 찾아보시길..)

## 카프카 스트림즈 : 아키텍처 개요

### 토폴로지 생성하기

모든 스트림즈 애플리케이션은 하나의 토폴로지를 구현하고 실행한다. 토폴로지는 다른 스트림 처리 프레임워크에서는 DAG 혹은 유향 비순환 그래프라고도 불리는데, 
모든 이벤트가 입력에서 출력으로 이동하는 동안 수행되는 작업과 변환 처리의 집합이다.

### 토폴로지 최적화 하기

기본적으로 카프카 스트림즈는 DSL API를 사용해서 개발된 애플리케이션의 각 DSL 메서드를 독립적으로 저수준 API로 변환해서 실행한다.
각각의 DSL 메서드를 독립적으로 변환하기 때문에 결과 토폴로지는 전체적으로 그리 최적화되지 않은 상태일 수 있다.

하지만, 카프카 스트림즈의 애플리케이션의 실행은 아래 3단계로 이루어진다.

 - KStream, KTable 객체를 생성 후 여기에 작업을 수행해 논리적 토폴로지 정의
 - StreamsBuilder.build() 메서드가 논리적 토폴로지로 부터 물리적 토폴로지 생성
 - KafkaStreams.start() 가 토폴로지를 실행시킨다.

논리적 토폴로지에서 물리적 토폴로지가 생성되는 두 번째 단계가 최적화가 적용되는 곳이다.

아파치 카프카는 몇 개의 최적화 방식을 포함하고 있을 뿐이다. `StreamsConfig.TOPOLOGEY_OPTIMIZATION` 설정을 수정하여 사용할 수 있다.

--- 
(이후 내용은 이론적인 얘기보단 사용 사례 중심으로 이루어져 있어 skip)