# 챕터 8. '정확히 한 번' 의미 구조

챕터 7 에서는 카프카는 '최소 한 번' 전달에 초점을 맞췄다. 하지만 메시지 중복의 가능성은 여전히 있다.
메시지 중복은 쉽게 처리 할 수 있는 간단한 문제다. 현실에서 사용하는 대부분의 애플리케이션은 중복 메시지를 제거할 수 있도록 고유한 식별자를 포함한다.

이 장에서는 카프카의 **'정확히 한 번'** 의미 구조를 사용하는 방법과 활용 사례, 한계를 알아본다.

## 멱등적 프로듀서

동일한 작업을 여러번 실행해도 결과가 같은 것을 **멱등적 (idempotent)** 이라고 한다.

> #### Q. 멱등성이란?
> 멱등성은 같은 요청을 여러 번 실행해도 결과가 변하지 않는 성질을 말한다. 
> 시스템에서 멱등성은 중복 요청으로 인한 오류를 방지하고 데이터 무결성을 보장하며, 
> 네트워크 장애나 재시도 상황에서도 안전하게 동작할 수 있게 한다.
> 
> ex) 엘리베이터 버튼을 여러 번 눌러도 엘리베이터는 한 번만 호출 됨 

멱등성 의미 구조가 아닌 **'최소 한 번'**의 의미 구조를 가지도록 프로듀서를 설정한다면 메시지 중복이 일어날 수 있다.
카프카의 멱등적 프로듀서 기능은 자동으로 이런 중복을 탐지하여 문제를 해결한다.

### 멱등적 프로듀서 작동 원리

멱등성 프로듀서 기능을 켜면 모든 메시지는 고유한 프로듀서 ID와 시퀀스 넘버를 가지게 된다. 토픽 및 파티션과 이 두 값을 합치면 각 메시지의 고유한 식별자가 된다.
각 브로커는 해당 브로커에 할당 된 모든 파티션들에 쓰여진 마지막 5개 메시지들을 추적하기 위해 이 고유 식별자를 사용한다.

브로커가 예전에 받은 적이 있는 메시지를 받게 될 경우, 적절한 에러를 발생시킨다. 

> #### Q. 브로커가 예상보다 높은 시퀀스 넘버를 받게 된다면?
> 브로커는 2번 뒤 3번이 올 것이라 예상하지만, 27번 메시지가 오게 된다면 브로커는 'out of sequence number' 에러를 발생시킨다.
> 이 에러는 프로듀서와 브로커 사이 메시지 유실이 있었음을 의미한다.

멱등적 프로듀서는 작동이 실패했을 때 아래 케이스에 대해 다음과 같이 작동한다.

#### 프로듀서 재 시작

보통 새 프로듀서를 만들어서 장애가 난 프로듀서를 대체한다. 여기서 중요한 점은 프로듀서가 시작 될 때 멱등적 프로듀서 기능이 켜져 있을 경우 프로듀서 ID를 할당받는다.
즉, 프로듀서에 장애가 발생해 기존 프로듀서가 이미 전송한 메시지를 다시 전송할 경우 브로커는 메시지에 중복이 있음을 알아채지 못한다.

#### 브로커 장애

브로커 장애가 발생할 경우 컨트롤러는 리더를 새로 선출한다. 새로 선출 된 리더 레플리카는 이미 팔로워 레플리카였던 시점에 자체적으로 최근 5개의 시퀀스 넘버를 같이 업데이트 받는다.
그 결과로 새롭게 리더가 선출되어도 시퀀스 넘버를 유지할 수 있다.

이 상태에서 기존 리더가 다시 돌아온다면, 일단 파일에서 최신 상태를 읽고, (현재 변경 된)리더 레플리카에게 프로듀서 상태를 다시 읽어온다.

### 멱등적 프로듀서의 한계

멱등적 프로듀서는 내부 로직으로 인한 재시도가 발생할 경우 생기는 중복만 방지한다. 그냥 producer가 send를 두번 이상 호출 하는 경우는 멱등적 프로듀서가 개입할 수 없다.
또한, 여러개의 인스턴스를 띄우는 경우도 흔하다. 이럴 경우 다수의 인스턴스에서 중복 메시지를 보내는 것을 알 수 없다.

### 멱등적 프로듀서 사용 법

간단하게 아래 설정을 추가하므로써 사용할 수 있다.

``` properties
enable.idempotence=true
```

다음 옵션을 활성화 하면 아래와 같은 내용이 변경된다.
- 프로듀서 아이디를 받아오기 위해 프로듀서 시동 과정에서 API를 한번 더 호출한다.
- 각각의 레코드 배치에는 첫 메시지의 시퀀스 넘버가 포함된다.
- 브로커는 모든 메시지를 검증해 중복을 방지한다.
- 장애가 발생해도 메시지의 순서가 보장된다.

## 트랜잭션

카프카의 트랜잭션은 카프카 스트림즈를 사용하는 애플리케이션에 정확성을 보장하기 위해 도입되었다.
각 입력 레코드는 '정확히 한 번' 처리되어야 하며, 처리 결과 역시 한 번만 반영되어야 한다.

> #### Q. 스트림즈 애플리케이션?
> 스트림즈 애플리케이션은 '읽기 - 처리 - 쓰기' 패턴을 제공하는 애플리케이션이다. 위의 트랜잭션 기능은 이러한 상황에서 '정확히 한 번' 의미 구조를 보장한다.

### 트랜잭션 활용 사례

정확성이 중요한 스트림 처리 애플리케이션이라면 언제나 큰 도움이 된다.
금융 애플리케이션은 '정확히 한 번' 기능이 정확한 집적 결과를 보장하는데 쓰이는 전형적인 예다.

### 트랜잭션이 해결하는 문제

단순한 스트림 애플리케이션을 생각해 보자. 원본 토픽으로부터 데이터를 읽어서, 처리를 한 다음 다른 토픽에 결과를 쓴다.
각 처리하는 메시지를 한번만 쓰여지도록 하고 싶다. 무엇이 잘못 될 수 있을까?

#### 애플리케이션 크래시로 인한 재시작

애플리케이션은 두 가지를 해야한다. 하나는 결과를 출력 토픽에 쓰는거고, 하나는 오프셋을 커밋하는 것이다.
출력 토픽에는 썼으나 오프셋을 커밋하지 못한다면 중복이 발생할 가능성이 있다.

#### 좀비 애플리케이션에 의해 발생하는 재처리

애플리케이션이 카프카로부터 데이터를 읽어온 직후 카프카로의 연결이 끊긴다면 어떻게 될까?

기본적으로 리밸런싱이 수행되며 다른 컨슈머에서 데이터를 재처리 하겠지만, 기존 컨슈머가 다시 돌아오는 경우 중복 문제가 발생한다.

### 트랜잭션은 어떻게 '정확히 한 번'을 보장하는가?

우리는 스트림즈 애플리케이션의 경우 부분적인 결과가 발생하지 않을 것 이라는 보장이 필요하다.
이것을 해결하기 위해 카프카는 **원자적 다수 파티션 쓰기(atomic multipartition write)** 기능을 도입했다.

이 아이디어는 오프셋을 커밋하는 것과 결과를 쓰는 것은 둘 다 파티션에 메시지를 쓰는 과정을 수반한다는 점에 착안했다. 결과는 출력 토픽에,
오프셋은 **__consumer_offset** 토픽에 쓰여진다는 점만 다르다.

트랜젹션을 시작해서 양쪽에 메시지를 쓰고, 둘 다 성공해서 커밋할 수 있다면 '정확히 한 번'의미 구조가 알아서 처리해준다.

트랜잭션을 사용해서 원자적 다수 파티션 쓰기를 수행하려면 **트랜잭션적 프로듀서**를 사용해야 한다. 보통 프로듀서와의 차이점은 **transactional.id** 설정이 잡혀 있고, 초기화 하는 과정이 추가 될 뿐이다.
**transactional.id** 설정은 재시작 후에도 동일한 프로듀서를 식별하는 용도다.

좀비 인스턴스가 중복 프로듀서를 생성하는 것을 방지하기 위해 카프카는 초기화 과정에서 **transactional.id** 에포크 값을 증가시킨다. **transactional.id**를 가지고 있지만 에포크 값이 낮은 프로듀서는 무시한다.

트랜잭션은 대부분 프로듀서 기능이다. 트랜잭션 기능을 사용해서 쓰여진 레코드들은 결국 파티션에 쓰여진다. 컨슈머에 올바른 격리 수준이 설정되어 있지 않다면 '정확히 한 번' 보장은 이루어지지 않는다.

#### isolation.level

이 값은 메시지를 읽어오는 방식을 제어할 수 있다.

- read_committed : 토픽들을 구독한 뒤 poll을 호출하면 커밋된 트랜잭션에 속한 메시지나 처음부터 트랜잭션에 속하지 않은 메시지만 리턴된다.
- read_uncommitted : 모든 레코드가 리턴된다.

> #### Q. Kafka에서 "커밋된 메시지"의 의미
> Kafka의 트랜잭션에서 **커밋**은 메시지가 **정상적으로 완료된 작업**임을 나타낸다.
> 프로듀서가 데이터를 브로커에 전송한 뒤, 트랜잭션이 성공적으로 끝나면 해당 메시지는 **커밋됨** 상태가 된다.
> 반대로 트랜잭션이 실패하거나 롤백되면 해당 메시지는 유효하지 않은 상태로 간주한다.
> 
> ex) 프로듀서가 메시지 A와 B를 전송. 트랜잭션을 커밋하면 A와 B는 커밋된 메시지가 된다. 트랜잭션이 롤백되면 A와 B는 유효하지 않으며, read_committed 모드에서는 보이지 않는다.

### 트랜잭션으로 해결할 수 없는 문제들

트랜잭션 기능은 다수에 파티션에 대한 원자적 쓰기 기능을 제공하고, 좀비 프로듀서를 방지하기 위한 목적으로 추가되었다.
결과적으로, '읽기 - 처리 - 쓰기' 스트림 처리 작업에서 사용 될 때 한 번 처리됨을 보장한다.

이 부분에서 자주 하는 실수가 두가지 있다. 하나는 '정확히 한 번 보장'이 카프카에 대한 쓰기 이외에 작동에서도 보장된다고 착각하는 것이다.
또 다른 하나는 컨슈머가 항상 전체 트랜잭션을 읽어온다고 가정하는 것이다.

아래는 카프카의 트랜잭션 기능이 '정확히 한 번' 보장에 도움이 되지 않는 몇 가지 경우다.

#### 스트림 처리에 있어서의 side effect

스트림 처리 단계의 사용자에게 이메일을 보내는 경우가 있다고 가정해보자. 정확히 한 번 의미구조를 활성화 해도 이메일이 한 번만 발송되는 것은 아니다.
이 기능은 카프카에 쓰여지는 레코드에만 적용된다. 이는 스트림 처리 애플리케이션 안에서 작동하는 어떠한 작업에도 해당된다.

#### 카프카 토픽에서 읽어 데이터베이스에 쓰는 경우

이 경우에는 외부 데이터베이스에 결과물을 쓴다. 이때는 프로듀서가 사용되지 않는다.
하나의 트랜잭션에서 외부 DB에 결과물을 쓰고 오프셋을 커밋하는 매커니즘은 없다.

#### 데이터베이스에서 읽어, 카프카에 쓰고, 다른 데이터베이스에 쓰는 경우

카프카 트랜잭션은 이러한 종류의 종단 보장을 지원하지 않는다. 카프카 컨슈머의 read_committed는 데이터베이스 트랜잭션을 보관하기에는 너무 약하다.

#### 한 클러스터에서 다른 클러스터로 데이터 복제

클러스터로의 데이터 복제는 한번을 보장할 수 있지만, 이것이 트랜잭션의 원자성을 보장하지는 않는다. 

#### 발행/구독 패턴

발행/구독 패턴은 매우 일반적인 활용 사례다. 이 경우에는 스트림즈 애플리케이션이 아니기에 큰 의미가 없다.
다만 read_committed 옵션을 사용하는 컨슈머들은 중단 된 트랜잭션에 속한 레코드를 보지 못 할 것이다. 하지만 이것은 '정확히 한 번'을 보장하지 못한다.

### 트랜잭션 사용법

**필요한 경우 카프카 스트림즈의 exactly-once 옵션을 키면 간단하다.**

(예제는 책 참고)

### 트랜잭션 ID와 펜싱

프로듀서가 사용할 트랜잭션 ID를 선택하는 것은 중요할 뿐 아니라 보기보다 조금 더 어렵다.
핵심 요구 조건은 동일 인스턴스가 재시작 되었을 때 유지되어야 하지만, 다른 애플리케이션 인스턴스에 대해서는 서로 달라야 한다.

현재는 트랜잭션 아이디와 컨슈머 그룹 메타데이터를 함께 사용하는 펜싱을 도입했다. 여기서는 프로듀서의 오프셋 커밋 메서드를 호출할 때 단순한 컨슈머 그룹 아이디가 아닌, 컨슈머 그룹 메타 데이터를 인수로 받는다.
이때 컨슈머 그룹 메타데이터는 에포크 값을 포함하므로 어느 세대에서 온 데이터인지 유추할 수 있다.

### 트랜잭션의 작동 원리
 
기본적인 알고리즘은 **찬디-램포트 스냅샷** 알고리즘의 영향을 받았다. 이 알고리즘은 통신 채널을 통해 마커라는 컨트롤 메시지를 보내고, 이 마커의 도착을 기준으로 일관적인 상태를 결정한다.

카프카의 트랜잭션은 다수에 파티션에 대해 트랜잭션이 커밋되었거나 중단되었다는 것을 표시하기 위해 마커를 보낸다.
트랜잭션 코디네이터에게 메시지를 보내면 트랜잭션 코디네이터가 트랜잭션에 관련된 모든 파티션에 커밋 마커를 쓴다.
하지만 일부 파티션에만 커밋 마커가 쓰여진 상태로 프로듀서가 크래시 나면 어떻게 될까?

카프카 트랜잭션은 **2단계 커밋**과 **트랜잭션 로그**를 사용해서 이 문제를 해결한다.

- 1. 진행중인 트랜잭션이 존재함을 로그에 기록한다. (연관된 파티션도 같이 기록한다.)
- 2. 로그에 커밋 혹은 중단 시도를 기록한다. (로그에 남으면 최종적으로는 커밋되거나 중단되어야 한다.)
- 3. 모든 파티션에 트랜잭션 마커에 쓴다.
- 4. 트랜잭션이 종료되었음을 로그에 쓴다. 

이 기본적인 알고리즘을 구현하기 위해 카프카는 트랜잭션 로그를 필요로 한다. 내부적으로는 **__transaction_state**라는 내부 토픽을 사용한다.

### 트랜잭션 성능

트랜잭션은 프로듀서에 약간의 오버헤드를 발생시킨다. 프로듀서를 생성해서 사용하는 동안 아이디 등록 요청은 단 한번 발생한다ㅣ.
각 트랜잭션이 커밋 요청을 전송하면 파티션마다 커밋 마커가 추가된다. 트랜잭션 초기화와 커밋 요청은 동기적으로 동작하기 때문에 성공적으로 완료되거나, 실패하거나, 타임아웃 나거나 할 때까지 어떤 데이터도 전송되지 않는다.

프로듀서에 있어서 트랜잭션 오버헤드는 트랜잭션에 포함 된 메시지의 수와는 무관하다는 점을 명심하라. 그렇기 때문에 트랜잭션마다 많은 수의 메시지를 집어 넣는 쪽이 상대적으로 오버헤드가 적다.
